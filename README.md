# model_compression
This project is a combination case of model compression algorithm，which use pruning, quantification and distillation.


Requirements
pytorch = 1.0
python3.5
ubuntu16.04
cuda8.0

Reference 
https://github.com/antspy/quantized_distillation
https://github.com/wanglouis49/pytorch-weights_pruning

The project is divided into two parts, the first step is pruning, and the second step is quantification + distillation.
You need to import the pruned model into the quantization file for quantification.


Contact information：976160664@qq.com
